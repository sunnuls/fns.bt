# ‚ö° –°–æ–≤–µ—Ç—ã –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

## üéØ –¶–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

1. **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ** - 11/10 –≤–∏–∑—É–∞–ª—å–Ω–æ
2. **–ü—Ä–∏–µ–º–ª–µ–º–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å** - –Ω–µ –±–æ–ª–µ–µ 60-90 —Å–µ–∫—É–Ω–¥ –Ω–∞ –≤–∏–¥–µ–æ
3. **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ VRAM** - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ GPU —Å 16GB+

## üîß –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

### 1. xformers (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!)

**–≠—Ñ—Ñ–µ–∫—Ç:** –£—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–æ 2x, —Å–Ω–∏–∂–µ–Ω–∏–µ VRAM –Ω–∞ 30%

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞
pip install xformers==0.0.23

# –ü—Ä–æ–≤–µ—Ä–∫–∞
python -c "import xformers; print('xformers OK')"
```

**–ï—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è:**
```bash
# –î–ª—è CUDA 12.1
pip install xformers==0.0.23+cu121 --index-url https://download.pytorch.org/whl/cu121

# –î–ª—è CUDA 11.8
pip install xformers==0.0.23+cu118 --index-url https://download.pytorch.org/whl/cu118
```

### 2. TF32 –¥–ª—è Ampere GPU (RTX 30xx, 40xx, A100)

**–≠—Ñ—Ñ–µ–∫—Ç:** –£—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ 30-50%

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –∫–æ–¥–µ:
```python
if torch.cuda.get_device_capability()[0] >= 8:
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True
```

### 3. VAE Slicing

**–≠—Ñ—Ñ–µ–∫—Ç:** –°–Ω–∏–∂–µ–Ω–∏–µ VRAM –Ω–∞ 20-40%

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–µ–Ω–æ:
```python
pipeline.vae.enable_slicing()
```

### 4. Attention Slicing

**–≠—Ñ—Ñ–µ–∫—Ç:** –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ VRAM –Ω–∞ 10-20%

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–µ–Ω–æ:
```python
pipeline.enable_attention_slicing()
```

## üìä –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö GPU

### RTX 3090 / 4090 (24GB VRAM)

**–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**
```python
# config.py
FPS = 24
STEPS = 40
ENHANCE_OUTPUT = True

# renderer.py
decode_chunk_size = 8
```

**–û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- 720p, 6s: ~25-30 —Å–µ–∫—É–Ω–¥
- 1080p, 6s: ~35-45 —Å–µ–∫—É–Ω–¥
- 1080p, 12s: ~60-80 —Å–µ–∫—É–Ω–¥

### RTX 3080 / 4080 (16GB VRAM)

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**
```python
# config.py
FPS = 24
STEPS = 35  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 40
ENHANCE_OUTPUT = True

# renderer.py
decode_chunk_size = 6  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 8
```

**–û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- 720p, 6s: ~30-35 —Å–µ–∫—É–Ω–¥
- 1080p, 6s: ~45-55 —Å–µ–∫—É–Ω–¥

### RTX 3070 / 4070 (12GB VRAM)

**–ö–æ–º–ø—Ä–æ–º–∏—Å—Å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**
```python
# config.py
FPS = 24
STEPS = 30
ENHANCE_OUTPUT = True

# renderer.py
decode_chunk_size = 4
```

**–û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- 720p, 6s: ~35-40 —Å–µ–∫—É–Ω–¥
- 1080p: –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ 720p)

### RTX 3060 (12GB VRAM) / RTX 4060 (8GB VRAM)

**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**
```python
# config.py
FPS = 18  # –£–º–µ–Ω—å—à–µ–Ω–æ
STEPS = 25
ENHANCE_OUTPUT = False  # –û—Ç–∫–ª—é—á–µ–Ω–∞ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞

# renderer.py
decode_chunk_size = 2
```

**–û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- 720p, 6s: ~45-60 —Å–µ–∫—É–Ω–¥
- 360p, 6s: ~25-30 —Å–µ–∫—É–Ω–¥

## üöÄ –û–±–ª–∞—á–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

### RunPod

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
- GPU: RTX 4090 –∏–ª–∏ A100
- Storage: 100GB
- –¶–µ–Ω–∞: $0.34-0.79/—á–∞—Å

**–ö–æ–º–∞–Ω–¥—ã:**
```bash
# –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
bash runpod_setup.sh

# –ò–ª–∏ Docker
docker-compose up -d
```

### Vast.ai

**–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä:**
- GPU: RTX 3090 (–¥–µ—à–µ–≤–ª–µ 4090, –ø–æ—á—Ç–∏ —Ç–∞ –∂–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
- Spot instance: —ç–∫–æ–Ω–æ–º–∏—è –¥–æ 70%
- –¶–µ–Ω–∞: $0.15-0.25/—á–∞—Å

**–§–∏–ª—å—Ç—Ä—ã –ø–æ–∏—Å–∫–∞:**
- VRAM >= 20GB
- CUDA >= 12.0
- Upload speed >= 100 Mbps

### Lambda Labs

**–î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:**
- GPU: A100 (40GB)
- –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: 99.9%
- –¶–µ–Ω–∞: $0.80-1.10/—á–∞—Å

## üí° –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

### 1. –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –º–æ–¥–µ–ª—å —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è (~7GB). –£—Å–∫–æ—Ä—å—Ç–µ:

```bash
# –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞—á–∞—Ç—å
python -c "
from diffusers import StableVideoDiffusionPipeline
StableVideoDiffusionPipeline.from_pretrained(
    'stabilityai/stable-video-diffusion-img2vid-xt',
    cache_dir='./cache/models'
)
"
```

### 2. Torch Compile (PyTorch 2.0+)

**–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ:** –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–æ 20%

```python
# –í renderer.py –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏:
self.pipeline.unet = torch.compile(self.pipeline.unet, mode="reduce-overhead")
```

‚ö†Ô∏è –ü–µ—Ä–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç –¥–æ–ª–≥–æ–π (–∫–æ–º–ø–∏–ª—è—Ü–∏—è), –Ω–æ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ - –±—ã—Å—Ç—Ä–µ–µ.

### 3. Batch Processing

–ï—Å–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç–µ –º–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏–π:

```python
# –í worker/tasks.py
# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞–Ω–∏–π –ø–æ–¥—Ä—è–¥ –±–µ–∑ –≤—ã–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
# –ú–æ–¥–µ–ª—å –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏ –º–µ–∂–¥—É –∑–∞–¥–∞–Ω–∏—è–º–∏
```

### 4. Quality Profiles

–°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ—Ñ–∏–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤:

```python
# config.py
class QualityProfiles:
    ULTRA = {"steps": 50, "fps": 30, "enhance": True}
    HIGH = {"steps": 40, "fps": 24, "enhance": True}   # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    MEDIUM = {"steps": 30, "fps": 24, "enhance": True}
    FAST = {"steps": 25, "fps": 18, "enhance": False}
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –í–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:

```bash
# –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
watch -n 1 nvidia-smi

# –û–±—Ä–∞—â–∞–π—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞:
# - GPU Utilization (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 90-100%)
# - Memory Usage (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 100%)
# - Temperature (< 85¬∞C –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)
```

### –ú–µ—Ç—Ä–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏:

```python
# –í renderer.py —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:
# [GENERATING] Video: 6s @ 1280x720
# [INFERENCE] Running with 40 steps, 144 frames...
# Step 1/40 completed
# ...
# [ENCODING] Using high-quality H.264 encoding...
# [SUCCESS] Video generated: output.mp4
#            Frames: 144, FPS: 24, Duration: 6s
```

## üéõÔ∏è –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### Motion Bucket ID

–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è:

```python
# –í config.py –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ preset:
MOTION_PRESETS = {
    "micro": {"motion_bucket_id": 50},      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
    "pan_l": {"motion_bucket_id": 100},     # –£–º–µ—Ä–µ–Ω–Ω–æ–µ
    "dolly_in": {"motion_bucket_id": 127},  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ
}
```

### Noise Augmentation Strength

–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å/—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å:

```python
# –ú–µ–Ω—å—à–µ = –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ, –Ω–æ –º–µ–Ω–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ
noise_aug_strength = 0.05  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ

# –ë–æ–ª—å—à–µ = –±–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ, –Ω–æ –º–µ–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ
noise_aug_strength = 0.15  # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ
```

### FFmpeg Encoding

–ë–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞:

```python
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã)
'-crf', '15', '-preset', 'veryslow'

# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
'-crf', '18', '-preset', 'slow'

# –ë—ã—Å—Ç—Ä–æ–µ (–º–µ–Ω—å—à–∏–µ —Ñ–∞–π–ª—ã)
'-crf', '23', '-preset', 'medium'
```

## üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º

### GPU –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å CUDA
python -c "import torch; print(torch.cuda.is_available())"

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—Ä–∞–π–≤–µ—Ä
nvidia-smi

# –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å PyTorch
pip install torch torchvision --force-reinstall --index-url https://download.pytorch.org/whl/cu121
```

### Out of Memory

1. –£–º–µ–Ω—å—à–∏—Ç—å `decode_chunk_size`
2. –£–º–µ–Ω—å—à–∏—Ç—å `STEPS`
3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à–µ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
4. –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ xformers —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å xformers: `python -c "import xformers"`
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å GPU utilization: `nvidia-smi`
3. –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞ GPU, –Ω–µ CPU
4. –û—Ç–∫–ª—é—á–∏—Ç—å –¥—Ä—É–≥–∏–µ GPU –ø—Ä–æ—Ü–µ—Å—Å—ã

## üìä –ë–µ–Ω—á–º–∞—Ä–∫–∏

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π (RTX 4090, 1080p, 6s):

| –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è | –í—Ä–µ–º—è | VRAM | Speedup |
|-------------|-------|------|---------|
| –ë–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è | 90s | 24GB | 1.0x |
| + Attention slicing | 88s | 20GB | 1.02x |
| + VAE slicing | 85s | 18GB | 1.06x |
| + xformers | 50s | 18GB | 1.8x |
| + TF32 | 35s | 18GB | 2.6x |
| + All optimizations | 35s | 16GB | 2.6x |

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π (RTX 4090, 6s, –≤—Å–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏):

| –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ | –í—Ä–µ–º—è | VRAM | –ö–∞—á–µ—Å—Ç–≤–æ |
|------------|-------|------|----------|
| 360p | 15s | 12GB | 8/10 |
| 480p | 20s | 14GB | 9/10 |
| 720p | 25s | 16GB | 10/10 |
| 1080p | 35s | 18GB | 11/10 |

---

**–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Å —É–º–æ–º! ‚ö°üöÄ**

